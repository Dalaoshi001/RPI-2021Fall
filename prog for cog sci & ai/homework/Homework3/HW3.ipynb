{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "624px",
        "left": "936px",
        "right": "20px",
        "top": "107px",
        "width": "380px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZuh-y0KVuhd"
      },
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et0TeGbuVuhf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snwGPjyEemL8"
      },
      "source": [
        "## Homework 3\n",
        "\n",
        "Due 12/10 10am. No submissions will be accepted after 12/13 9am.\n",
        "\n",
        "In this  homework you will create CNN models of the CIFAR-10 and CIFAR-100 datasets which are available as PyTorch and Tensorflow datasets. Info about these datasets can be found at https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "All parts must be able to run on Google colab using GPUs.\n",
        "\n",
        "**All work must be your own work.** If you copy something from the internet, include the link.\n",
        "\n",
        "Make sure all the output is shown.\n",
        "\n",
        "Name your submission your_rcsid_HW3.ipynb\n",
        "\n",
        "There are three parts to the assignment:\n",
        "\n",
        "1) Tensorflow Model (40 pts)  \n",
        "2) Pytorch Model (40 pts)  \n",
        "3) Pretrained Mode (20 pts)  \n",
        "\n",
        "Points for each part are in () after the part number.\n",
        "\n",
        "### 1. Tensorflow Model\n",
        "\n",
        "#### 1.1(1) Tensorflow imports\n",
        "\n",
        "Display Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YtMVRzjfVuhi",
        "outputId": "c65ea3e9-c4c6-4cce-c062-e3152bfe5795"
      },
      "source": [
        "# Your Code Here\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__\n",
        "\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4VTw3OeH5G"
      },
      "source": [
        "#### 1.2(2) Load the CIFAR10 data into Training and Test sets. Display the shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MPZGR32Vuhi",
        "outputId": "e6043704-cb36-4c02-86ee-6ab648b49811"
      },
      "source": [
        "# Your Code Here\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train = y_train.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000,), (10000, 32, 32, 3), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owVOwWI-Vuhl"
      },
      "source": [
        "#### 1.3(2) Data Preprocessing\n",
        "Reshape each image to a 4-d array, convert to floating point and scale.\n",
        "\n",
        "Display 5 training values and 5 test values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au0DCWX0Vuhl",
        "outputId": "29d8bc68-9eef-4949-8932-7de888e9a842"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_train[16:22], X_test[16:22] "
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[0.92156863, 0.9254902 , 0.93333334],\n",
              "          [0.92156863, 0.9254902 , 0.93333334],\n",
              "          [0.92941177, 0.93333334, 0.9411765 ],\n",
              "          ...,\n",
              "          [0.9137255 , 0.91764706, 0.9254902 ],\n",
              "          [0.8901961 , 0.9019608 , 0.9137255 ],\n",
              "          [0.8745098 , 0.89411765, 0.9098039 ]],\n",
              " \n",
              "         [[0.90588236, 0.9098039 , 0.91764706],\n",
              "          [0.9098039 , 0.9137255 , 0.92156863],\n",
              "          [0.91764706, 0.92156863, 0.92941177],\n",
              "          ...,\n",
              "          [0.90588236, 0.9098039 , 0.91764706],\n",
              "          [0.88235295, 0.89411765, 0.9098039 ],\n",
              "          [0.8666667 , 0.88235295, 0.9137255 ]],\n",
              " \n",
              "         [[0.90588236, 0.9098039 , 0.91764706],\n",
              "          [0.9137255 , 0.91764706, 0.9254902 ],\n",
              "          [0.92941177, 0.93333334, 0.9411765 ],\n",
              "          ...,\n",
              "          [0.9098039 , 0.9137255 , 0.92156863],\n",
              "          [0.88235295, 0.89411765, 0.9098039 ],\n",
              "          [0.8666667 , 0.8862745 , 0.9137255 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.49019608, 0.4862745 , 0.47843137],\n",
              "          [0.49411765, 0.49019608, 0.48235294],\n",
              "          [0.56078434, 0.5568628 , 0.54901963],\n",
              "          ...,\n",
              "          [0.25882354, 0.34901962, 0.09019608],\n",
              "          [0.25490198, 0.3372549 , 0.09019608],\n",
              "          [0.26666668, 0.3254902 , 0.14509805]],\n",
              " \n",
              "         [[0.49803922, 0.49019608, 0.49019608],\n",
              "          [0.5529412 , 0.54901963, 0.54509807],\n",
              "          [0.58431375, 0.5803922 , 0.5803922 ],\n",
              "          ...,\n",
              "          [0.24705882, 0.34901962, 0.09411765],\n",
              "          [0.2627451 , 0.34509805, 0.10196079],\n",
              "          [0.24313726, 0.30980393, 0.11372549]],\n",
              " \n",
              "         [[0.5372549 , 0.5294118 , 0.53333336],\n",
              "          [0.5568628 , 0.54901963, 0.5529412 ],\n",
              "          [0.58431375, 0.5764706 , 0.5803922 ],\n",
              "          ...,\n",
              "          [0.24313726, 0.3529412 , 0.10588235],\n",
              "          [0.23921569, 0.32941177, 0.09019608],\n",
              "          [0.2       , 0.26666668, 0.05490196]]],\n",
              " \n",
              " \n",
              "        [[[0.43137255, 0.40784314, 0.38039216],\n",
              "          [0.5568628 , 0.5294118 , 0.4627451 ],\n",
              "          [0.5921569 , 0.57254905, 0.47058824],\n",
              "          ...,\n",
              "          [0.15294118, 0.15294118, 0.15294118],\n",
              "          [0.15686275, 0.15686275, 0.15686275],\n",
              "          [0.14901961, 0.14901961, 0.14901961]],\n",
              " \n",
              "         [[0.42745098, 0.40392157, 0.37254903],\n",
              "          [0.5529412 , 0.52156866, 0.4509804 ],\n",
              "          [0.59607846, 0.5764706 , 0.46666667],\n",
              "          ...,\n",
              "          [0.14117648, 0.14117648, 0.14509805],\n",
              "          [0.15686275, 0.15686275, 0.15686275],\n",
              "          [0.14117648, 0.14117648, 0.14117648]],\n",
              " \n",
              "         [[0.4117647 , 0.38431373, 0.3529412 ],\n",
              "          [0.5568628 , 0.52156866, 0.44705883],\n",
              "          [0.5921569 , 0.5686275 , 0.45882353],\n",
              "          ...,\n",
              "          [0.15294118, 0.15294118, 0.16078432],\n",
              "          [0.17254902, 0.17254902, 0.1764706 ],\n",
              "          [0.15294118, 0.15294118, 0.15686275]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.24313726, 0.23137255, 0.23529412],\n",
              "          [0.15294118, 0.14901961, 0.19215687],\n",
              "          [0.23529412, 0.2509804 , 0.31764707],\n",
              "          ...,\n",
              "          [0.16470589, 0.17254902, 0.21960784],\n",
              "          [0.18039216, 0.17254902, 0.21568628],\n",
              "          [0.18431373, 0.17254902, 0.21568628]],\n",
              " \n",
              "         [[0.24313726, 0.22352941, 0.21960784],\n",
              "          [0.20392157, 0.2       , 0.23921569],\n",
              "          [0.22745098, 0.23921569, 0.30588236],\n",
              "          ...,\n",
              "          [0.16862746, 0.18039216, 0.22745098],\n",
              "          [0.18431373, 0.1764706 , 0.22745098],\n",
              "          [0.19215687, 0.18039216, 0.23529412]],\n",
              " \n",
              "         [[0.21568628, 0.2       , 0.19607843],\n",
              "          [0.23529412, 0.23529412, 0.2784314 ],\n",
              "          [0.21960784, 0.23529412, 0.30588236],\n",
              "          ...,\n",
              "          [0.1764706 , 0.1882353 , 0.23529412],\n",
              "          [0.18431373, 0.18039216, 0.23529412],\n",
              "          [0.2       , 0.1882353 , 0.24313726]]],\n",
              " \n",
              " \n",
              "        [[[0.77254903, 0.73333335, 0.7372549 ],\n",
              "          [0.7764706 , 0.7372549 , 0.7411765 ],\n",
              "          [0.7882353 , 0.7490196 , 0.7529412 ],\n",
              "          ...,\n",
              "          [0.8509804 , 0.7882353 , 0.8       ],\n",
              "          [0.8509804 , 0.7882353 , 0.8       ],\n",
              "          [0.8509804 , 0.7882353 , 0.8       ]],\n",
              " \n",
              "         [[0.75686276, 0.7176471 , 0.72156864],\n",
              "          [0.7647059 , 0.7254902 , 0.7294118 ],\n",
              "          [0.7764706 , 0.7372549 , 0.7411765 ],\n",
              "          ...,\n",
              "          [0.84705883, 0.78431374, 0.79607844],\n",
              "          [0.84313726, 0.78431374, 0.7921569 ],\n",
              "          [0.8392157 , 0.7764706 , 0.7882353 ]],\n",
              " \n",
              "         [[0.7529412 , 0.7137255 , 0.7176471 ],\n",
              "          [0.7607843 , 0.72156864, 0.7254902 ],\n",
              "          [0.77254903, 0.73333335, 0.7372549 ],\n",
              "          ...,\n",
              "          [0.8509804 , 0.7882353 , 0.8       ],\n",
              "          [0.84705883, 0.78431374, 0.79607844],\n",
              "          [0.84313726, 0.78039217, 0.7921569 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.6117647 , 0.57254905, 0.5764706 ],\n",
              "          [0.6117647 , 0.57254905, 0.5764706 ],\n",
              "          [0.6117647 , 0.57254905, 0.5764706 ],\n",
              "          ...,\n",
              "          [0.38431373, 0.30980393, 0.25490198],\n",
              "          [0.45882353, 0.3764706 , 0.32156864],\n",
              "          [0.5019608 , 0.4117647 , 0.34901962]],\n",
              " \n",
              "         [[0.61960787, 0.5803922 , 0.58431375],\n",
              "          [0.62352943, 0.58431375, 0.5882353 ],\n",
              "          [0.6039216 , 0.5647059 , 0.5686275 ],\n",
              "          ...,\n",
              "          [0.5137255 , 0.43137255, 0.3764706 ],\n",
              "          [0.45882353, 0.3882353 , 0.3372549 ],\n",
              "          [0.35686275, 0.29411766, 0.2509804 ]],\n",
              " \n",
              "         [[0.59607846, 0.5568628 , 0.56078434],\n",
              "          [0.5921569 , 0.5529412 , 0.5568628 ],\n",
              "          [0.5686275 , 0.5294118 , 0.53333336],\n",
              "          ...,\n",
              "          [0.35686275, 0.28235295, 0.23921569],\n",
              "          [0.3529412 , 0.28627452, 0.24705882],\n",
              "          [0.30980393, 0.25490198, 0.22352941]]],\n",
              " \n",
              " \n",
              "        [[[0.09019608, 0.10588235, 0.08627451],\n",
              "          [0.18431373, 0.19215687, 0.16078432],\n",
              "          [0.20392157, 0.18039216, 0.11764706],\n",
              "          ...,\n",
              "          [0.5137255 , 0.50980395, 0.45882353],\n",
              "          [0.7137255 , 0.7058824 , 0.68235296],\n",
              "          [0.84313726, 0.83137256, 0.9019608 ]],\n",
              " \n",
              "         [[0.1254902 , 0.12156863, 0.09411765],\n",
              "          [0.2       , 0.19215687, 0.14901961],\n",
              "          [0.21960784, 0.19215687, 0.13333334],\n",
              "          ...,\n",
              "          [0.58431375, 0.5803922 , 0.52156866],\n",
              "          [0.8       , 0.80784315, 0.77254903],\n",
              "          [0.81960785, 0.8509804 , 0.9098039 ]],\n",
              " \n",
              "         [[0.16078432, 0.14509805, 0.09803922],\n",
              "          [0.23137255, 0.22352941, 0.18431373],\n",
              "          [0.23529412, 0.23137255, 0.2       ],\n",
              "          ...,\n",
              "          [0.5411765 , 0.5411765 , 0.49019608],\n",
              "          [0.76862746, 0.78431374, 0.7607843 ],\n",
              "          [0.79607844, 0.8509804 , 0.9137255 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.654902  , 0.654902  , 0.65882355],\n",
              "          [0.69411767, 0.69411767, 0.69411767],\n",
              "          [0.7137255 , 0.7137255 , 0.7137255 ],\n",
              "          ...,\n",
              "          [0.78039217, 0.7529412 , 0.7529412 ],\n",
              "          [0.6901961 , 0.67058825, 0.67058825],\n",
              "          [0.5686275 , 0.54901963, 0.54901963]],\n",
              " \n",
              "         [[0.6509804 , 0.6509804 , 0.6509804 ],\n",
              "          [0.64705884, 0.64705884, 0.64705884],\n",
              "          [0.64705884, 0.64705884, 0.64705884],\n",
              "          ...,\n",
              "          [0.7176471 , 0.70980394, 0.70980394],\n",
              "          [0.7176471 , 0.7137255 , 0.7137255 ],\n",
              "          [0.7411765 , 0.73333335, 0.7372549 ]],\n",
              " \n",
              "         [[0.6862745 , 0.6862745 , 0.6862745 ],\n",
              "          [0.6784314 , 0.6784314 , 0.6784314 ],\n",
              "          [0.6784314 , 0.6784314 , 0.6784314 ],\n",
              "          ...,\n",
              "          [0.74509805, 0.73333335, 0.72156864],\n",
              "          [0.7372549 , 0.7294118 , 0.7176471 ],\n",
              "          [0.7529412 , 0.7411765 , 0.7294118 ]]],\n",
              " \n",
              " \n",
              "        [[[0.6       , 0.6156863 , 0.60784316],\n",
              "          [0.68235296, 0.7058824 , 0.7372549 ],\n",
              "          [0.60784316, 0.64705884, 0.6745098 ],\n",
              "          ...,\n",
              "          [0.47843137, 0.49019608, 0.48235294],\n",
              "          [0.5411765 , 0.56078434, 0.5529412 ],\n",
              "          [0.38039216, 0.39607844, 0.38039216]],\n",
              " \n",
              "         [[0.627451  , 0.6392157 , 0.64705884],\n",
              "          [0.6431373 , 0.6666667 , 0.7058824 ],\n",
              "          [0.5882353 , 0.62352943, 0.6627451 ],\n",
              "          ...,\n",
              "          [0.5372549 , 0.5294118 , 0.5058824 ],\n",
              "          [0.627451  , 0.6313726 , 0.6156863 ],\n",
              "          [0.40392157, 0.42745098, 0.41960785]],\n",
              " \n",
              "         [[0.54901963, 0.56078434, 0.5764706 ],\n",
              "          [0.5764706 , 0.59607846, 0.6509804 ],\n",
              "          [0.53333336, 0.5686275 , 0.61960787],\n",
              "          ...,\n",
              "          [0.40784314, 0.40392157, 0.3882353 ],\n",
              "          [0.49019608, 0.5019608 , 0.49019608],\n",
              "          [0.3647059 , 0.4       , 0.39607844]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.6862745 , 0.69411767, 0.7019608 ],\n",
              "          [0.6666667 , 0.6745098 , 0.68235296],\n",
              "          [0.6666667 , 0.6745098 , 0.68235296],\n",
              "          ...,\n",
              "          [0.75686276, 0.79607844, 0.83137256],\n",
              "          [0.77254903, 0.80784315, 0.8392157 ],\n",
              "          [0.78039217, 0.8       , 0.8352941 ]],\n",
              " \n",
              "         [[0.68235296, 0.69411767, 0.70980394],\n",
              "          [0.6784314 , 0.6901961 , 0.7058824 ],\n",
              "          [0.67058825, 0.68235296, 0.69803923],\n",
              "          ...,\n",
              "          [0.78431374, 0.8156863 , 0.84705883],\n",
              "          [0.7921569 , 0.81960785, 0.85490197],\n",
              "          [0.8156863 , 0.83137256, 0.8666667 ]],\n",
              " \n",
              "         [[0.65882355, 0.6784314 , 0.7058824 ],\n",
              "          [0.6431373 , 0.6627451 , 0.6862745 ],\n",
              "          [0.6509804 , 0.67058825, 0.69411767],\n",
              "          ...,\n",
              "          [0.8       , 0.81960785, 0.8509804 ],\n",
              "          [0.8       , 0.8156863 , 0.8509804 ],\n",
              "          [0.80784315, 0.8235294 , 0.85882354]]],\n",
              " \n",
              " \n",
              "        [[[0.9882353 , 0.03137255, 0.16470589],\n",
              "          [0.9764706 , 0.05882353, 0.16470589],\n",
              "          [0.98039216, 0.03137255, 0.15294118],\n",
              "          ...,\n",
              "          [0.9843137 , 0.00392157, 0.04313726],\n",
              "          [0.9843137 , 0.        , 0.05882353],\n",
              "          [0.9843137 , 0.00392157, 0.11764706]],\n",
              " \n",
              "         [[1.        , 0.02745098, 0.16862746],\n",
              "          [0.9882353 , 0.05882353, 0.17254902],\n",
              "          [0.99215686, 0.05098039, 0.16470589],\n",
              "          ...,\n",
              "          [1.        , 0.00392157, 0.04313726],\n",
              "          [1.        , 0.        , 0.07058824],\n",
              "          [0.99607843, 0.01568628, 0.12941177]],\n",
              " \n",
              "         [[0.99215686, 0.02352941, 0.16470589],\n",
              "          [0.98039216, 0.0627451 , 0.16470589],\n",
              "          [0.98039216, 0.09411765, 0.16862746],\n",
              "          ...,\n",
              "          [0.99607843, 0.00392157, 0.03921569],\n",
              "          [0.99607843, 0.        , 0.07843138],\n",
              "          [0.9882353 , 0.03529412, 0.14509805]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.99607843, 0.25882354, 0.36862746],\n",
              "          [0.9882353 , 0.24313726, 0.36078432],\n",
              "          [0.99215686, 0.2509804 , 0.3647059 ],\n",
              "          ...,\n",
              "          [0.9882353 , 0.27450982, 0.39607844],\n",
              "          [0.99215686, 0.27058825, 0.40392157],\n",
              "          [0.9882353 , 0.27450982, 0.40784314]],\n",
              " \n",
              "         [[0.98039216, 0.19215687, 0.31764707],\n",
              "          [0.9882353 , 0.20784314, 0.32156864],\n",
              "          [1.        , 0.23137255, 0.3372549 ],\n",
              "          ...,\n",
              "          [0.99607843, 0.27450982, 0.40392157],\n",
              "          [1.        , 0.26666668, 0.39215687],\n",
              "          [0.99607843, 0.23137255, 0.34901962]],\n",
              " \n",
              "         [[0.9254902 , 0.14509805, 0.26666668],\n",
              "          [0.9764706 , 0.1882353 , 0.29803923],\n",
              "          [0.98039216, 0.16470589, 0.28627452],\n",
              "          ...,\n",
              "          [0.98039216, 0.30588236, 0.44313726],\n",
              "          [0.98039216, 0.2901961 , 0.42745098],\n",
              "          [0.9843137 , 0.22745098, 0.34509805]]]], dtype=float32),\n",
              " array([[[[0.37254903, 0.29803923, 0.30588236],\n",
              "          [0.36078432, 0.3019608 , 0.30588236],\n",
              "          [0.34901962, 0.3019608 , 0.3019608 ],\n",
              "          ...,\n",
              "          [0.11764706, 0.10980392, 0.14901961],\n",
              "          [0.6862745 , 0.7176471 , 0.7490196 ],\n",
              "          [0.88235295, 0.91764706, 0.9411765 ]],\n",
              " \n",
              "         [[0.3529412 , 0.2784314 , 0.28627452],\n",
              "          [0.3372549 , 0.28235295, 0.28235295],\n",
              "          [0.3254902 , 0.2784314 , 0.2784314 ],\n",
              "          ...,\n",
              "          [0.        , 0.        , 0.05098039],\n",
              "          [0.23529412, 0.24705882, 0.30980393],\n",
              "          [0.64705884, 0.67058825, 0.7411765 ]],\n",
              " \n",
              "         [[0.34509805, 0.27058825, 0.2784314 ],\n",
              "          [0.32941177, 0.27450982, 0.27450982],\n",
              "          [0.32156864, 0.27450982, 0.27450982],\n",
              "          ...,\n",
              "          [0.01960784, 0.        , 0.04705882],\n",
              "          [0.09411765, 0.10196079, 0.1882353 ],\n",
              "          [0.49803922, 0.54509807, 0.64705884]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.79607844, 0.6901961 , 0.6313726 ],\n",
              "          [0.8352941 , 0.6862745 , 0.6117647 ],\n",
              "          [0.7921569 , 0.64705884, 0.60784316],\n",
              "          ...,\n",
              "          [0.7137255 , 0.7176471 , 0.7411765 ],\n",
              "          [0.4627451 , 0.47058824, 0.49019608],\n",
              "          [0.14509805, 0.1254902 , 0.18039216]],\n",
              " \n",
              "         [[0.48235294, 0.36862746, 0.3529412 ],\n",
              "          [0.8235294 , 0.6666667 , 0.6156863 ],\n",
              "          [0.827451  , 0.67058825, 0.627451  ],\n",
              "          ...,\n",
              "          [0.45490196, 0.45490196, 0.47058824],\n",
              "          [0.17254902, 0.1764706 , 0.18431373],\n",
              "          [0.04313726, 0.01176471, 0.05882353]],\n",
              " \n",
              "         [[0.4       , 0.33333334, 0.32941177],\n",
              "          [0.8156863 , 0.7176471 , 0.6862745 ],\n",
              "          [0.84313726, 0.7294118 , 0.6901961 ],\n",
              "          ...,\n",
              "          [0.14509805, 0.12941177, 0.16862746],\n",
              "          [0.06666667, 0.05098039, 0.08627451],\n",
              "          [0.08627451, 0.04313726, 0.10980392]]],\n",
              " \n",
              " \n",
              "        [[[0.23529412, 0.5019608 , 0.5764706 ],\n",
              "          [0.27058825, 0.5254902 , 0.6156863 ],\n",
              "          [0.2784314 , 0.49803922, 0.5882353 ],\n",
              "          ...,\n",
              "          [0.3372549 , 0.43529412, 0.42352942],\n",
              "          [0.3254902 , 0.40784314, 0.42352942],\n",
              "          [0.4117647 , 0.4862745 , 0.52156866]],\n",
              " \n",
              "         [[0.24313726, 0.5176471 , 0.5764706 ],\n",
              "          [0.27450982, 0.5372549 , 0.6117647 ],\n",
              "          [0.30980393, 0.5411765 , 0.6156863 ],\n",
              "          ...,\n",
              "          [0.34117648, 0.42745098, 0.42352942],\n",
              "          [0.36862746, 0.44313726, 0.4509804 ],\n",
              "          [0.5529412 , 0.61960787, 0.64705884]],\n",
              " \n",
              "         [[0.23921569, 0.49411765, 0.54901963],\n",
              "          [0.27450982, 0.5176471 , 0.5921569 ],\n",
              "          [0.33333334, 0.54901963, 0.61960787],\n",
              "          ...,\n",
              "          [0.4627451 , 0.5411765 , 0.5411765 ],\n",
              "          [0.5294118 , 0.59607846, 0.6039216 ],\n",
              "          [0.7254902 , 0.78431374, 0.79607844]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.39215687, 0.3529412 , 0.29411766],\n",
              "          [0.75686276, 0.7647059 , 0.7019608 ],\n",
              "          [0.84705883, 0.8627451 , 0.8156863 ],\n",
              "          ...,\n",
              "          [0.81960785, 0.8117647 , 0.77254903],\n",
              "          [0.80784315, 0.8       , 0.7490196 ],\n",
              "          [0.80784315, 0.8       , 0.7411765 ]],\n",
              " \n",
              "         [[0.6666667 , 0.6509804 , 0.62352943],\n",
              "          [0.8392157 , 0.83137256, 0.80784315],\n",
              "          [0.8235294 , 0.8156863 , 0.7921569 ],\n",
              "          ...,\n",
              "          [0.80784315, 0.79607844, 0.75686276],\n",
              "          [0.8       , 0.7921569 , 0.74509805],\n",
              "          [0.8117647 , 0.8039216 , 0.7490196 ]],\n",
              " \n",
              "         [[0.80784315, 0.79607844, 0.78039217],\n",
              "          [0.827451  , 0.8156863 , 0.8       ],\n",
              "          [0.8352941 , 0.8235294 , 0.8039216 ],\n",
              "          ...,\n",
              "          [0.827451  , 0.8156863 , 0.7764706 ],\n",
              "          [0.8235294 , 0.8156863 , 0.7647059 ],\n",
              "          [0.83137256, 0.8235294 , 0.76862746]]],\n",
              " \n",
              " \n",
              "        [[[0.8745098 , 0.88235295, 0.972549  ],\n",
              "          [0.8745098 , 0.88235295, 0.95686275],\n",
              "          [0.88235295, 0.89411765, 0.9529412 ],\n",
              "          ...,\n",
              "          [0.8901961 , 0.9019608 , 0.96862745],\n",
              "          [0.8745098 , 0.88235295, 0.9607843 ],\n",
              "          [0.85882354, 0.8666667 , 0.9607843 ]],\n",
              " \n",
              "         [[0.88235295, 0.8901961 , 0.9882353 ],\n",
              "          [0.88235295, 0.8901961 , 0.972549  ],\n",
              "          [0.8901961 , 0.9019608 , 0.972549  ],\n",
              "          ...,\n",
              "          [0.91764706, 0.93333334, 0.972549  ],\n",
              "          [0.9098039 , 0.9254902 , 0.972549  ],\n",
              "          [0.89411765, 0.90588236, 0.96862745]],\n",
              " \n",
              "         [[0.8784314 , 0.88235295, 0.9882353 ],\n",
              "          [0.8784314 , 0.8862745 , 0.972549  ],\n",
              "          [0.8901961 , 0.9019608 , 0.98039216],\n",
              "          ...,\n",
              "          [0.9254902 , 0.94509804, 0.9647059 ],\n",
              "          [0.91764706, 0.93333334, 0.96862745],\n",
              "          [0.8980392 , 0.9137255 , 0.9607843 ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.04313726, 0.03137255, 0.0627451 ],\n",
              "          [0.03137255, 0.03921569, 0.07450981],\n",
              "          [0.23529412, 0.28235295, 0.35686275],\n",
              "          ...,\n",
              "          [0.08627451, 0.22352941, 0.27058825],\n",
              "          [0.11764706, 0.27058825, 0.32941177],\n",
              "          [0.28627452, 0.44705883, 0.53333336]],\n",
              " \n",
              "         [[0.03921569, 0.03529412, 0.05882353],\n",
              "          [0.03921569, 0.04313726, 0.07843138],\n",
              "          [0.2       , 0.2509804 , 0.31764707],\n",
              "          ...,\n",
              "          [0.11764706, 0.25882354, 0.3137255 ],\n",
              "          [0.11372549, 0.26666668, 0.33333334],\n",
              "          [0.23921569, 0.40392157, 0.49019608]],\n",
              " \n",
              "         [[0.03921569, 0.04313726, 0.06666667],\n",
              "          [0.03529412, 0.05490196, 0.08627451],\n",
              "          [0.14509805, 0.21176471, 0.27450982],\n",
              "          ...,\n",
              "          [0.10196079, 0.23921569, 0.30980393],\n",
              "          [0.10980392, 0.25490198, 0.32941177],\n",
              "          [0.21960784, 0.37254903, 0.4627451 ]]],\n",
              " \n",
              " \n",
              "        [[[0.21568628, 0.14901961, 0.18039216],\n",
              "          [0.2       , 0.12941177, 0.17254902],\n",
              "          [0.19607843, 0.12156863, 0.1764706 ],\n",
              "          ...,\n",
              "          [0.50980395, 0.3764706 , 0.28235295],\n",
              "          [0.47843137, 0.3529412 , 0.2627451 ],\n",
              "          [0.48235294, 0.3529412 , 0.2901961 ]],\n",
              " \n",
              "         [[0.2       , 0.12941177, 0.16470589],\n",
              "          [0.1764706 , 0.10588235, 0.14901961],\n",
              "          [0.21176471, 0.13725491, 0.18039216],\n",
              "          ...,\n",
              "          [0.43529412, 0.33333334, 0.2627451 ],\n",
              "          [0.56078434, 0.4392157 , 0.3254902 ],\n",
              "          [0.5411765 , 0.41568628, 0.30980393]],\n",
              " \n",
              "         [[0.1764706 , 0.10980392, 0.12941177],\n",
              "          [0.20784314, 0.14117648, 0.14901961],\n",
              "          [0.24313726, 0.19215687, 0.18431373],\n",
              "          ...,\n",
              "          [0.41960785, 0.34117648, 0.22745098],\n",
              "          [0.4       , 0.2901961 , 0.20392157],\n",
              "          [0.5137255 , 0.40784314, 0.31764707]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.49411765, 0.4       , 0.28627452],\n",
              "          [0.52156866, 0.41960785, 0.2627451 ],\n",
              "          [0.63529414, 0.4745098 , 0.28235295],\n",
              "          ...,\n",
              "          [0.75686276, 0.67058825, 0.43137255],\n",
              "          [0.83137256, 0.7176471 , 0.58431375],\n",
              "          [0.8235294 , 0.7137255 , 0.5764706 ]],\n",
              " \n",
              "         [[0.5568628 , 0.43529412, 0.28627452],\n",
              "          [0.50980395, 0.36862746, 0.21568628],\n",
              "          [0.6431373 , 0.44313726, 0.25882354],\n",
              "          ...,\n",
              "          [0.8352941 , 0.7647059 , 0.47058824],\n",
              "          [0.84705883, 0.74509805, 0.54509807],\n",
              "          [0.85882354, 0.7411765 , 0.59607846]],\n",
              " \n",
              "         [[0.61960787, 0.5058824 , 0.38431373],\n",
              "          [0.6392157 , 0.49803922, 0.3372549 ],\n",
              "          [0.7019608 , 0.49803922, 0.34901962],\n",
              "          ...,\n",
              "          [0.8862745 , 0.827451  , 0.6039216 ],\n",
              "          [0.8862745 , 0.8352941 , 0.627451  ],\n",
              "          [0.84313726, 0.7411765 , 0.5803922 ]]],\n",
              " \n",
              " \n",
              "        [[[0.1882353 , 0.19215687, 0.1882353 ],\n",
              "          [0.25490198, 0.26666668, 0.2627451 ],\n",
              "          [0.32941177, 0.34901962, 0.34117648],\n",
              "          ...,\n",
              "          [0.23921569, 0.24705882, 0.23137255],\n",
              "          [0.19215687, 0.19607843, 0.18039216],\n",
              "          [0.1764706 , 0.1764706 , 0.16470589]],\n",
              " \n",
              "         [[0.05490196, 0.05098039, 0.05098039],\n",
              "          [0.0627451 , 0.05882353, 0.05098039],\n",
              "          [0.07450981, 0.07450981, 0.05882353],\n",
              "          ...,\n",
              "          [0.11764706, 0.1254902 , 0.10980392],\n",
              "          [0.07843138, 0.08627451, 0.06666667],\n",
              "          [0.09019608, 0.09019608, 0.07843138]],\n",
              " \n",
              "         [[0.11764706, 0.15294118, 0.09411765],\n",
              "          [0.14117648, 0.15294118, 0.10588235],\n",
              "          [0.1254902 , 0.12941177, 0.08235294],\n",
              "          ...,\n",
              "          [0.11372549, 0.12156863, 0.10588235],\n",
              "          [0.08627451, 0.09411765, 0.07450981],\n",
              "          [0.09019608, 0.09411765, 0.07450981]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.5176471 , 0.5882353 , 0.38039216],\n",
              "          [0.5137255 , 0.58431375, 0.38039216],\n",
              "          [0.5137255 , 0.58431375, 0.3882353 ],\n",
              "          ...,\n",
              "          [0.62352943, 0.654902  , 0.654902  ],\n",
              "          [0.5882353 , 0.61960787, 0.6392157 ],\n",
              "          [0.5764706 , 0.59607846, 0.6156863 ]],\n",
              " \n",
              "         [[0.5058824 , 0.5764706 , 0.36862746],\n",
              "          [0.5137255 , 0.5803922 , 0.38431373],\n",
              "          [0.5058824 , 0.57254905, 0.3764706 ],\n",
              "          ...,\n",
              "          [0.6313726 , 0.654902  , 0.58431375],\n",
              "          [0.6509804 , 0.6784314 , 0.6392157 ],\n",
              "          [0.6627451 , 0.6745098 , 0.6784314 ]],\n",
              " \n",
              "         [[0.49803922, 0.57254905, 0.3647059 ],\n",
              "          [0.5294118 , 0.59607846, 0.40392157],\n",
              "          [0.53333336, 0.5921569 , 0.40784314],\n",
              "          ...,\n",
              "          [0.5647059 , 0.5882353 , 0.4392157 ],\n",
              "          [0.54901963, 0.57254905, 0.4509804 ],\n",
              "          [0.5686275 , 0.58431375, 0.49411765]]],\n",
              " \n",
              " \n",
              "        [[[0.96862745, 0.9882353 , 0.9607843 ],\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          ...,\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          [0.9490196 , 0.96862745, 0.9411765 ],\n",
              "          [0.96862745, 0.9882353 , 0.9607843 ]],\n",
              " \n",
              "         [[0.96862745, 0.9882353 , 0.9607843 ],\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          ...,\n",
              "          [0.94509804, 0.9647059 , 0.9372549 ],\n",
              "          [0.94509804, 0.9647059 , 0.9372549 ],\n",
              "          [0.9647059 , 0.9843137 , 0.95686275]],\n",
              " \n",
              "         [[0.972549  , 0.99215686, 0.9647059 ],\n",
              "          [0.95686275, 0.9764706 , 0.9490196 ],\n",
              "          [0.95686275, 0.9764706 , 0.9490196 ],\n",
              "          ...,\n",
              "          [0.9529412 , 0.972549  , 0.94509804],\n",
              "          [0.9490196 , 0.96862745, 0.9411765 ],\n",
              "          [0.9647059 , 0.9843137 , 0.95686275]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.9647059 , 0.9764706 , 0.9490196 ],\n",
              "          [0.94509804, 0.95686275, 0.92941177],\n",
              "          [0.9490196 , 0.9607843 , 0.93333334],\n",
              "          ...,\n",
              "          [0.94509804, 0.9647059 , 0.9372549 ],\n",
              "          [0.94509804, 0.9607843 , 0.93333334],\n",
              "          [0.96862745, 0.98039216, 0.9529412 ]],\n",
              " \n",
              "         [[0.9607843 , 0.972549  , 0.94509804],\n",
              "          [0.94509804, 0.95686275, 0.92941177],\n",
              "          [0.94509804, 0.95686275, 0.92941177],\n",
              "          ...,\n",
              "          [0.94509804, 0.9647059 , 0.9372549 ],\n",
              "          [0.94509804, 0.9607843 , 0.93333334],\n",
              "          [0.9647059 , 0.9764706 , 0.9490196 ]],\n",
              " \n",
              "         [[0.9607843 , 0.972549  , 0.94509804],\n",
              "          [0.9490196 , 0.9607843 , 0.93333334],\n",
              "          [0.9490196 , 0.9607843 , 0.93333334],\n",
              "          ...,\n",
              "          [0.9411765 , 0.9647059 , 0.9372549 ],\n",
              "          [0.9411765 , 0.95686275, 0.92941177],\n",
              "          [0.9647059 , 0.9764706 , 0.9490196 ]]]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjM7yMS4Vuhm"
      },
      "source": [
        "#### 1.4(2) Encode the dependent variable. \n",
        "\n",
        "Display the shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJyWjcORVuhm",
        "outputId": "ab05a259-10b3-4d9f-8f29-5b882e992b6b"
      },
      "source": [
        "# Your Code Here\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "y_train_one_hot.shape, y_test_one_hot.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svrq_cn4Vuhm"
      },
      "source": [
        "#### 1.5(2) Split training data into training data and validation data. \n",
        "\n",
        "Use 20% of the data for validation. Display the shapes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMwi5EmkVuhm",
        "outputId": "85a75273-3450-49e2-b6fe-11100c217708"
      },
      "source": [
        "# Your Code Here\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=13)\n",
        "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 32, 32, 3), (10000, 32, 32, 3), (40000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kde8OfJIVuhn"
      },
      "source": [
        "#### 1.6 (15) Specify model structure\n",
        "\n",
        "Create a Tensorflow model. Experiment with different layer structures to optimize classification performance.\n",
        "\n",
        "Keep your best one here. Summarize your results in question 1.13."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K_8AkKQVuhn"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "from tensorflow.keras.models import Sequential,Model \n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.models import load_model,save_model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(32,32,3),\n",
        "                     padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.1))                  \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=0.1))                  \n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74dOdUlEemMC"
      },
      "source": [
        "#### 1.7(2) Output a model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh2IX6NVVuhn",
        "outputId": "14502547-a03c-4e67-a64f-2d347e9bbf43"
      },
      "source": [
        "# Your Code Here\n",
        "model.summary()\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_25 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_26 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               262272    \n",
            "                                                                 \n",
            " leaky_re_lu_27 (LeakyReLU)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,810\n",
            "Trainable params: 356,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va04yO9qVuho"
      },
      "source": [
        "#### 1.8(2) Compile Model with Adam optimizer\n",
        "\n",
        "Use appropriate loss function and use 'accuracy' as metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-MqHTfRVuho"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlRwHzWpVuho"
      },
      "source": [
        "#### 1.9(2) Train the model with training and validation data.\n",
        "\n",
        "Experiment with different batch sizes. Summarize your results in 1.13."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nakJrVdVuho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80a94f6-dad9-403a-975b-5aa67be2a9d9"
      },
      "source": [
        "# Your Code Here\n",
        "batch_size = 64 #128,256 # Minibatch size\n",
        "epochs = 10\n",
        "model_train = model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,\n",
        "                        validation_data=(valid_X, valid_label))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.4291 - accuracy: 0.4829 - val_loss: 1.1172 - val_accuracy: 0.5956\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.9890 - accuracy: 0.6543 - val_loss: 0.9186 - val_accuracy: 0.6758\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.8026 - accuracy: 0.7211 - val_loss: 0.8255 - val_accuracy: 0.7135\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.6777 - accuracy: 0.7610 - val_loss: 0.8394 - val_accuracy: 0.7084\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5619 - accuracy: 0.8026 - val_loss: 0.7734 - val_accuracy: 0.7403\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4626 - accuracy: 0.8374 - val_loss: 0.7846 - val_accuracy: 0.7433\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3735 - accuracy: 0.8684 - val_loss: 0.8652 - val_accuracy: 0.7415\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2925 - accuracy: 0.8978 - val_loss: 0.9246 - val_accuracy: 0.7369\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2222 - accuracy: 0.9228 - val_loss: 1.0115 - val_accuracy: 0.7373\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.1783 - accuracy: 0.9373 - val_loss: 1.0768 - val_accuracy: 0.7319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz060dEKemMD"
      },
      "source": [
        "#### 1.10(1) Plot the training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "8u6IIL0AVuhp",
        "outputId": "01f48953-f1e5-438d-a163-6e19049a89a0"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "accuracy = model_train.history['accuracy']\n",
        "val_accuracy = model_train.history['val_accuracy']\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend();"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfoqoIX4Vuho"
      },
      "source": [
        "#### 1.11(2) Evaluate model on the test set\n",
        "\n",
        "Display test loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfi24m2SVuho",
        "outputId": "b14076f5-8cd3-4a83-e9db-c12d20839c93"
      },
      "source": [
        "# Your Code Here\n",
        "test_eval = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.113774299621582\n",
            "Test accuracy: 0.7232000231742859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isOClb_LVuhp"
      },
      "source": [
        "#### 1.12(2) Predict the classes of the test data\n",
        "\n",
        "Display Confusion Matrix and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAJZMRWjVuhq",
        "outputId": "b1b0e158-d88f-4d7a-d4ac-a4f460133ecc"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "predicted_classes = model.predict(X_test)\n",
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "cm = confusion_matrix(predicted_classes,y_test)\n",
        "print(cm)\n",
        "\n",
        "print(f'Accuracy: {np.trace(cm)/np.sum(cm)}')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[799  38 128 109  95  65  77  47  94  52]\n",
            " [  7 797   4   2   2   0   6   2  10  49]\n",
            " [ 59   8 581  42  65  25  28  18  18   4]\n",
            " [ 16  15  49 519  77 119  57  40  21  13]\n",
            " [  9   0  63  31 619  30  46  33   7   4]\n",
            " [  7  12  86 207  55 714  54  81   5  17]\n",
            " [ 10   3  36  35  21   8 711   5   3   2]\n",
            " [ 10   7  34  33  57  34   8 761   9  15]\n",
            " [ 34  18   8   5   6   0   7   3 798  14]\n",
            " [ 49 102  11  17   3   5   6  10  35 830]]\n",
            "Accuracy: 0.7129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cds2Pp3n7ayC"
      },
      "source": [
        "#### 1.13(5) Your summary of the experiments you conducted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRhCvNf98ajq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5XQcByleH5M"
      },
      "source": [
        "### 2. PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tccueiXeH5M"
      },
      "source": [
        "def conv_image_size(layers,size_in,padding=0,kernel=3,stride=2,dilation=1):\n",
        "    for _ in range(layers):\n",
        "        size_in = np.floor(((size_in+2*padding - dilation*(kernel-1)-1)/stride)+1)\n",
        "    return int(size_in)\n"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKhZJq5AAa7w"
      },
      "source": [
        "####  Install pytorch-model-summary if not installed. It is not installed in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoQNgt6eeH5M",
        "outputId": "fe889c25-357b-4a85-866c-98083f79008a"
      },
      "source": [
        "!pip install pytorch-model-summary\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-model-summary in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-model-summary) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFw_BL7ZeH5M"
      },
      "source": [
        "#### 2.1(1) PyTorch imports\n",
        "\n",
        "Display PyTorch Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2nHyhdZjxbL5",
        "outputId": "a6ec9a90-8fbb-4c9c-e704-df6215950814"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdhUcoJceH5M"
      },
      "source": [
        "#### 2.2(1) Set PyTorch device\n",
        "\n",
        "Display the device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-Fs4Z0RCfA"
      },
      "source": [
        "# Your Code Here\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_a6mOSeH5N"
      },
      "source": [
        "#### 2.3 (2) Load the CIFAR100 Training and Test datasets as tensors\n",
        "\n",
        "Display the data shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtsuCeN5xqyw",
        "outputId": "d9c5c977-cdea-4149-930b-2c7b2034071b"
      },
      "source": [
        "# Your Code Here\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='.',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='.',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True)\n",
        "\n",
        "trainset.data.shape, testset.data.shape"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKYv3XWHyjTL"
      },
      "source": [
        "#### 2.4 (10) Define and instantiate the model\n",
        "\n",
        "Create a PyTorch model. Experiment with different layer structures to optimize classification performance.\n",
        "\n",
        "Keep your best one here. Summarize your results in question 2.11.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf2d9f66x9wV"
      },
      "source": [
        "# Your Code Here\n",
        "import torch.nn as nn\n",
        "inp_sz = conv_image_size(3,32)\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, K):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv_layers = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    \n",
        "    self.flatten = nn.Flatten()\n",
        "    \n",
        "    self.dense_layers = nn.Sequential(\n",
        "      nn.Dropout(0.2),\n",
        "      nn.Linear(128 * inp_sz * inp_sz, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "      nn.Linear(512, K)\n",
        "    )\n",
        "   \n",
        "  \n",
        "  def forward(self, X):\n",
        "    z = self.conv_layers(X)\n",
        "    z = self.flatten(z)\n",
        "    out = self.dense_layers(z) # Softmax done in CrossEntopy Loss\n",
        "    return out\n",
        "model = CNN(100).to(device)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_PYSEMeH5O"
      },
      "source": [
        "#### 2.5(2) Print a summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGcs-W5Tgm1r",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f647ae-5410-4f0e-be8d-b166b0c73be3"
      },
      "source": [
        "# Your Code Here\n",
        "!pip install pytorch-model-summary\n",
        "from pytorch_model_summary import summary\n",
        "print(summary(model,torch.zeros((1,1,32,32)).to(device),show_input=False,show_hierarchical=False))\n"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-model-summary in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-model-summary) (3.10.0.2)\n",
            "-----------------------------------------------------------------------\n",
            "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "=======================================================================\n",
            "          Conv2d-1     [1, 32, 15, 15]             320             320\n",
            "            ReLU-2     [1, 32, 15, 15]               0               0\n",
            "          Conv2d-3       [1, 64, 7, 7]          18,496          18,496\n",
            "            ReLU-4       [1, 64, 7, 7]               0               0\n",
            "          Conv2d-5      [1, 128, 3, 3]          73,856          73,856\n",
            "            ReLU-6      [1, 128, 3, 3]               0               0\n",
            "         Flatten-7           [1, 1152]               0               0\n",
            "         Dropout-8           [1, 1152]               0               0\n",
            "          Linear-9            [1, 512]         590,336         590,336\n",
            "           ReLU-10            [1, 512]               0               0\n",
            "        Dropout-11            [1, 512]               0               0\n",
            "         Linear-12            [1, 100]          51,300          51,300\n",
            "=======================================================================\n",
            "Total params: 734,308\n",
            "Trainable params: 734,308\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcIQJicJ1sco"
      },
      "source": [
        "#### 2.6(1) Define Loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kcxTKNGeH5P"
      },
      "source": [
        "# Your Code Here\n",
        "criterion = nn.CrossEntropyLoss() # Applies the softmax function\n",
        "optimizer = torch.optim.Adam(model.parameters())\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YaUc5PN1_s0"
      },
      "source": [
        "#### 2.7 (2) Create Data loaders\n",
        "\n",
        "The data loader automatically generates batches in the training loop and takes care of shuffling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM90JdzTeH5P"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhY88SBVeH5P"
      },
      "source": [
        "### 2.8(5) Train the Model \n",
        "\n",
        "Display Epoch, train loss test loss and time of execution of epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUDs5Dju1yE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf0d614-7177-45d5-8e70-cf43cc884758"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "inp_sz = conv_image_size(3,32)\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, K):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv_layers = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    \n",
        "    self.flatten = nn.Flatten()\n",
        "    \n",
        "    self.dense_layers = nn.Sequential(\n",
        "      nn.Dropout(0.2),\n",
        "      nn.Linear(128 * inp_sz * inp_sz, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "      nn.Linear(512, K)\n",
        "    )\n",
        "   \n",
        "  \n",
        "  def forward(self, X):\n",
        "    z = self.conv_layers(X)\n",
        "    z = self.flatten(z)\n",
        "    out = self.dense_layers(z) # Softmax done in CrossEntopy Loss\n",
        "    return out\n",
        "model = CNN(100).to(device)\n",
        "\n",
        "def mini_batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs,device):\n",
        "  train_losses = np.zeros(epochs)\n",
        "  test_losses = np.zeros(epochs)\n",
        "\n",
        "  for it in range(epochs):\n",
        "    model.train() # Set training mode\n",
        "    t0 = datetime.now()\n",
        "    train_loss = []\n",
        "    for inputs, targets in train_loader:\n",
        "      # move data to device\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "     \n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "        \n",
        "      # Backward and optimize\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "    # Get train loss and test loss\n",
        "    \n",
        "    train_loss = np.mean(train_loss) \n",
        "    \n",
        "    test_loss = []\n",
        "    model.train(False) # Set test model aka model.eval()\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      test_loss.append(loss.item())\n",
        "    test_loss = np.mean(test_loss)\n",
        "\n",
        "    # Save losses\n",
        "    train_losses[it] = train_loss\n",
        "    test_losses[it] = test_loss\n",
        "    \n",
        "    dt = datetime.now() - t0\n",
        "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
        "  \n",
        "  return train_losses, test_losses\n",
        "\n",
        "train_losses, test_losses = mini_batch_gd(\n",
        "    model, criterion, optimizer, train_loader, test_loader, epochs=50,device=device)\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:22.199754\n",
            "Epoch 2/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.675566\n",
            "Epoch 3/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.769918\n",
            "Epoch 4/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.759446\n",
            "Epoch 5/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.501151\n",
            "Epoch 6/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.785083\n",
            "Epoch 7/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.644036\n",
            "Epoch 8/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.618678\n",
            "Epoch 9/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.915173\n",
            "Epoch 10/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.669747\n",
            "Epoch 11/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:22.055029\n",
            "Epoch 12/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.562385\n",
            "Epoch 13/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.464984\n",
            "Epoch 14/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.726702\n",
            "Epoch 15/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.663651\n",
            "Epoch 16/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.980206\n",
            "Epoch 17/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.537497\n",
            "Epoch 18/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.230666\n",
            "Epoch 19/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.177236\n",
            "Epoch 20/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.331894\n",
            "Epoch 21/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.591127\n",
            "Epoch 22/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.267004\n",
            "Epoch 23/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.062719\n",
            "Epoch 24/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.390156\n",
            "Epoch 25/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.076614\n",
            "Epoch 26/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.174414\n",
            "Epoch 27/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.275213\n",
            "Epoch 28/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.049356\n",
            "Epoch 29/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.262842\n",
            "Epoch 30/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.081571\n",
            "Epoch 31/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.027949\n",
            "Epoch 32/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.449580\n",
            "Epoch 33/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:20.980631\n",
            "Epoch 34/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.368665\n",
            "Epoch 35/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.204961\n",
            "Epoch 36/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.055427\n",
            "Epoch 37/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.068690\n",
            "Epoch 38/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.076494\n",
            "Epoch 39/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.311913\n",
            "Epoch 40/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.310172\n",
            "Epoch 41/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.566944\n",
            "Epoch 42/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.632695\n",
            "Epoch 43/50, Train Loss: 4.6055,       Test Loss: 4.6056, Duration: 0:00:21.778811\n",
            "Epoch 44/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:22.034765\n",
            "Epoch 45/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:22.099701\n",
            "Epoch 46/50, Train Loss: 4.6057,       Test Loss: 4.6056, Duration: 0:00:21.563626\n",
            "Epoch 47/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.463578\n",
            "Epoch 48/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.531156\n",
            "Epoch 49/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.745290\n",
            "Epoch 50/50, Train Loss: 4.6056,       Test Loss: 4.6056, Duration: 0:00:21.661411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9lcGrRs46LY"
      },
      "source": [
        "#### 2.9 (1) Plot the train loss and test loss per iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6zE87rGeH5Q"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrXa1RB-eH5Q"
      },
      "source": [
        "#### 2.10(10) Predict the Test Data \n",
        "\n",
        "Display Confusion Matrix and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj-sZUXZeH5Q"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOJmkwlo7ayE"
      },
      "source": [
        "#### 2.11(5) Your summary of the experiments you conducted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WkttpzOeH5Q"
      },
      "source": [
        "### 3.0 Pretrained\n",
        "\n",
        "#### 3.1 (1) Load a PyTorch pretrained ResNet50 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2f80b36-a0e9-4660-a399-8ae8e0103a97"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwUBwYspeH5Q"
      },
      "source": [
        "#### 3.2 (4) Print a summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bfec832-b849-410d-a3ae-7d56824349a4"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ris1H3-ReH5R"
      },
      "source": [
        "#### 3.3 (5) Modify model for CIFAR10 dataset. \n",
        "Set requires_grad attribute of all the parameters to False\n",
        "\n",
        "Replace last layer with a Linear Layer with the correct number of inputs and outputs.\n",
        "\n",
        "Hint: Use summary above and see https://discuss.pytorch.org/t/how-to-modify-the-final-fc-layer-based-on-the-torch-model/766"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24fb486a-ab93-4074-8bb7-c447446504fa"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1bFlimeeH5R"
      },
      "source": [
        "#### 3.4 (2) Send model to device and print summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5f8d14-2815-458f-ad08-50fb668e1ce0"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1ESfYneH5R"
      },
      "source": [
        "#### 3.5 (4) Load the CIFAR10 training dataset and retrain the model.\n",
        "\n",
        "Print the epoch, training loss and time of execution of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2308ff1-f63d-4ff3-96eb-382a5b268b50"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQnFKpgIeH5S"
      },
      "source": [
        "#### 3.6 (1) Plot the Training Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhyDtCxLjDBo"
      },
      "source": [
        "# Your Code Here\n",
        "\n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d9b7acb-7bdd-47c7-9062-b06031b30445"
      },
      "source": [
        "#### 3.7 (3) Load the test CIFAR10 dataset and predict the Test dataset.\n",
        "\n",
        "Display the Confusion Matrix and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87794034-53dc-498c-8bfb-ac8d54eca1e5"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "\n"
      ],
      "execution_count": 177,
      "outputs": []
    }
  ]
}