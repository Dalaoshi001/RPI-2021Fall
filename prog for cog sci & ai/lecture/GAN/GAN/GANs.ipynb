{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks (GANS)\n",
    "\n",
    "Generative Adversarial Nets(2014) Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair Aaron Courville, and Yoshua Bengio.   \n",
    "https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf  \n",
    "https://www.youtube.com/watch?v=eyxmSmjmNS0\n",
    "\n",
    "GANS are models with two parts. The goal is to produce realistic images by having the **Generator** create an image that the **Discriminator** classifies as either real or fake.\n",
    "\n",
    "Generative models learn p(y|x) by leaning P(x,y) =p(x|y)p(y). Discrimative models learn P(y|x) directly. We can sample from Generative Models since they learn p(y).\n",
    "\n",
    "GANs are trained by a zero-sum game between the Generator and the Discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](GAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "\n",
    "The generator takes random noise from some probability distribution as input and tries to generate a realistic output image\n",
    "\n",
    "$G(z,\\theta_g), z \\sim{N(0,1)} \\text{ or } z \\sim{U(-1,1)}$ is a sample from a Normal or Uniform distribution.\n",
    "\n",
    "\n",
    "#### Discriminator\n",
    "\n",
    "The Discriminator takes two alternating inputs: the real images of the training dataset or the generated fake samples from the generator. It classifies the input image as real or fake (i.e. comes from the Generator).\n",
    "\n",
    "$D(x,\\theta_d)$  \n",
    "\n",
    "Input: $z \\sim{p_g(z)}$ or $x \\sim{p_{data}(x)}$  \n",
    "Output: 1 = real, 0 = fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "#### Disciminator Loss Function\n",
    "\n",
    "For the Disciminator we want to minimize the loss function.\n",
    "\n",
    "$$L^{(D)} = \\mathbb{E}_{x\\sim{p_{data}}}log(D(x)) + \\mathbb{E}_{z\\sim{p_z}}log(1 - D(G(z))$$\n",
    "\n",
    "\n",
    "$\\mathbb{E}_{x\\sim{p_{data}}}log(D(x))$ is the loss when input is sampled from the real data. \n",
    "\n",
    "$\\mathbb{E}_{z\\sim{p_z}}log(1 - D(G(z))$ is the loss when the input is sampled from the Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generator Loss function\n",
    "\n",
    "$$L^{(G)} = \\mathbb{E}_{z\\sim{p_z}}log(1 - D(G(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN Objective Function\n",
    "\n",
    "Combining the Generator and Discriminator Loss Function\n",
    "\n",
    "$$\\underset{G}{\\mathrm{min}}\\text{ }\\underset{D}{\\mathrm{max}}V(G,D) = \\mathbb{E}_{x\\sim{p_{data}}}log(D(x)) + \\mathbb{E}_{z\\sim{p_z}}log(1 - D(G(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "These networks are hard to train. They are trained sequentially (i.e. one after the other), and alternate between the two over multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop\n",
    "\n",
    "1. Repeat for k steps, where k is a hyperparameter (set k = 1):  \n",
    "    - Sample a mini-batch of m noise samples $(z^{(1)},z^{(2)},...,z^{(m)})$ and transform with the Generator\n",
    "    - Sample a mini-batch of m samples from the real data, $(x^{(1)},x^{(2)},...,x^{(m)})$\n",
    "    - Update the discriminator weights $\\theta_d$ by **ascending** the stochastic gradient of its loss:\n",
    "$$\\nabla_{\\theta_d}\\frac{1}{m}\\sum_i^m[log(D(x^{(i)})) + log(1 - D(G(z^{(i)}))]$$\n",
    "    - The generator weights $\\theta_g$ will be locked and only the discriminator weights $\\theta_d$ are updated.\n",
    "    \n",
    "2. Sample a mini-batch of m noise samples $(z^{(1)},z^{(2)},...,z^{(m)})$ and transform with the Generator\n",
    "3.  Update the generator by **descending** the stochastic gradient of its loss:\n",
    "$$\\nabla_{\\theta_d}\\frac{1}{m}\\sum_i^m[ log(1 - D(G(z^{(i)}))]$$\n",
    "    - The discriminator weights $\\theta_d$  are locked and we can only adjust the Generator weights $\\theta_g$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Tricks \n",
    "\n",
    "\n",
    "* Training GANs is notoriously difficult, below are a few of the tricks (i.e. heuristics) to try\n",
    "\n",
    "* Use tanh as the last activation in the generator, instead of the sigmoid\n",
    "* Sample points from the latent space using a Gaussian not a uniform distribution.\n",
    "* Introduce randomness ways: \n",
    "    - Use dropout in the discriminator, \n",
    "    - Add some random noise to the labels for the discriminator.\n",
    "* Use LeakyReLU instead of a ReLU activation to ease sparsity constraints by allowing small negative activation values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sketch of proof that the Objective Function converge to $p_{data}(x) = p_g(x)$\n",
    "\n",
    "For complete derivation see https://www.youtube.com/watch?v=7G4_Y5rsvi8\n",
    "\n",
    "$$V(G,D) = \\mathbb{E}_{x\\sim{p_{data}}}log(D(x)) + \\mathbb{E}_{z\\sim{p_z}}log(1 - D(G(z)) \\\\\n",
    "=\\int_xp_{data}log(D(x))dx +  \\int_zp_zlog(1 - D(G(z))dz $$\n",
    "\n",
    "Rewrite in terms of x, using $z=G^{-1}(x), dx$ and $p_g$:\n",
    "\n",
    "$$=\\int_xp_{data}log(D(x))dx +  \\int_xp_x(G^{-1}(x))(log(1 - D(x))G^{-1}(x)dx \\\\\n",
    "=\\int_xp_{data}log(D(x))dx + \\int_xp_g(x)log(1 - D(x))dx$$\n",
    "\n",
    "\n",
    "\n",
    "Do optimization for max D\n",
    "\n",
    "$$\\underset{D}{\\mathrm{max}}V(D,G) = \\underset{D}{\\mathrm{max}}\\int_xp_{data}log(D(x)) + p_g(x)log(1 - D(x))dx$$\n",
    "\n",
    " i.e. set derivative = 0 and solve:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial D(x)}(p_{data}(x)log(D(x))) + p_g(x)log(1-D(x))) = 0 \\\\\n",
    "\\Rightarrow \\frac{p_{data}(x)}{D(x)} - \\frac{p_g(x)}{1 - D(x)} =0 \\\\\n",
    "\\Rightarrow D(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting D to the max value, $D^*_G(x)$, the loss function for G:\n",
    "\n",
    "$$L(G) = \\underset{D}{\\mathrm{max}}V(G,D) \\\\\n",
    "= \\underset{D}{\\mathrm{max}}\\int_xp_{data}log(D(x)) + p_g(x)log(1 - D(x))dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\int_xp_{data}log(D^*_G(x)) + p_g(x)log(1 - D^*_G(x))dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\int_xp_{data}log\\left(\\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\\right) + p_g(x)log\\left(1 - \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\\right)dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide each term by 2 and multiply by 2.\n",
    "\n",
    "$$ = \\int_xp_{data}log\\left(\\frac{p_{data}(x)}{\\frac{p_{data}(x) + p_g(x)}{2}}\\right) + p_g(x)log\\left(1 - \\frac{p_{data}(x)}{\\frac{p_{data}(x) + p_g(x)}{2}}\\right)dx -2log(2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is KL-divergence, so the Loss function for G:\n",
    "\n",
    "$$L(G)= KL[p_{data}(x)||\\frac{p_{data}(x) + p_g(x)}{2} ] + KL[p_g(x)||\\frac{p_{data}(x) + p_g(x)}{2}] - 2log2$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL-divergence is always $\\ge$ 0 therfore the minimum will be -2log(2). \n",
    "\n",
    "$$ \\underset{G}{\\mathrm{min}}L(G) = 0 + 0 - 2log(2) = -2log2 \\\\\n",
    "KL[p_{data}||\\frac{p_{data}(x) + p_g(x)}{2} ] = 0 \\\\\n",
    "\\text{when } p_{data} = \\frac{p_{data}(x) + p_g(x)}{2} $$\n",
    "\n",
    "Since KL-divergence can only = 0 when the distributions are equal, at the minimum, this implies:\n",
    "\n",
    "$$\\Rightarrow p_{data}(x) = p_g(x)$$\n",
    "\n",
    "The Discriminator will assign probability = .5 to real image and fake image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vasilev,Slatr,Spacagna,Roelants,Zocca (2019) Python Deep Learning, 2nd Edition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
