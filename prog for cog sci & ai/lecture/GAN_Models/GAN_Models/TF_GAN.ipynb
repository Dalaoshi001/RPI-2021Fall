{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U91-upG3aCG-"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from imutils import build_montages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os,sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "klEGNusAaCG_",
    "outputId": "0f2f17d4-f1e2-4e73-f871-68c747dc5190"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI9_kC76CKJb"
   },
   "source": [
    "## Tensorflow Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u1a3SYtCKJc"
   },
   "source": [
    "### DCGAN\n",
    "\n",
    "Radford, Metz & Chintala (2016) Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks. \n",
    "\n",
    "https://arxiv.org/pdf/1511.06434.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "95fzRFLdaCHA"
   },
   "outputs": [],
   "source": [
    "def build_generator(dim, depth, channels=1, \n",
    "                    inputDim=100,\n",
    "                    outputDim=512):\n",
    "    model = Sequential()\n",
    "    # Two Fully Connected layers with Batch Normalization\n",
    "    model.add(Dense(input_dim=inputDim, units=outputDim))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "  \n",
    "    model.add(Dense(dim * dim * depth))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Reshape the output of the previous layer, upsample\n",
    "    # apply a transposed convolution (i.e. deconvolution), RELU, and BN\n",
    "    model.add(Reshape((dim, dim, depth))) #Input shape\n",
    "    model.add(Conv2DTranspose(32, (5, 5), strides=(2, 2),\n",
    "                              padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    # Apply another upsample and transposed convolution, but\n",
    "    # with TANH activation\n",
    "    model.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2),\n",
    "                              padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YCJgFlECCKJd"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(width, height, depth, alpha=0.2):\n",
    "    model = Sequential()\n",
    "    # Two conv2d layers\n",
    "    model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
    "                     input_shape=(height, width, depth)))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    model.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    \n",
    "    # Flatten Layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #  One linear hidden layer with leaky relu\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    # output layer with sigmoid activation\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ52fsEWCKJd"
   },
   "source": [
    "#### Load the Fashion MNIST dataset\n",
    "* Stack the training and testing data points so we have additional training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UCS0w3CaCHA",
    "outputId": "34bc8b38-c334-48de-bf7b-75b5e5d7088f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
    "trainImages = np.concatenate([trainX, testX])\n",
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV8jSPHXCKJf"
   },
   "source": [
    "#### Preprocess\n",
    "\n",
    "Add in an extra dimension for the channel and scale the images\n",
    "into the range [-1, 1] (which is the range of the tanh function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwPPyGXGCKJf",
    "outputId": "c94207a4-670e-479b-830f-0e0ec8fc7f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainImages = np.expand_dims(trainImages, axis=-1)\n",
    "trainImages = (trainImages.astype(\"float\") - 127.5) / 127.5\n",
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2kAlnDqCKJf"
   },
   "source": [
    "#### Build models and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Df-uT0d4aCHA",
    "outputId": "c8622d0b-32e7-4459-b128-fe5d51a1e6d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0002\n",
    "num_epochs = 10\n",
    "\n",
    "G_model = build_generator(7, 64, channels=1)\n",
    "D_model = build_discriminator(28, 28, 1)\n",
    "D_model.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=Adam(lr=lr,beta_1=0.5,decay=lr/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhkJHzhMCKJf",
    "outputId": "0452fcdd-cb4f-4f55-c1ff-c2731d8bef3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               51712     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3136)              1608768   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 3136)              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3136)             12544     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 32)       51232     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 1)        801       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,727,233\n",
      "Trainable params: 1,719,873\n",
      "Non-trainable params: 7,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4nc8THlCKJg",
    "outputId": "38ecebd2-a69a-4367-955a-8a25baf1f609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          51264     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,658,753\n",
      "Trainable params: 1,658,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LivEO42xCKJg"
   },
   "source": [
    "#### Build the GAN model\n",
    "* Set the discriminator to **not** be trainable, i.e. freeze the weights\n",
    "* Compose  discriminator with the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I-kHs4JvaCHA"
   },
   "outputs": [],
   "source": [
    "D_model.trainable = False\n",
    "ganInput = Input(shape=(100,))\n",
    "ganOutput = D_model(G_model(ganInput))\n",
    "GAN_model = Model(ganInput, ganOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OHxY60OCKJg",
    "outputId": "c837c6ed-5e34-4e87-c86f-a6636f10ec77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 28, 28, 1)         1727233   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 1658753   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,385,986\n",
      "Trainable params: 1,719,873\n",
      "Non-trainable params: 1,666,113\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68jRb_SlCKJg",
    "outputId": "64d03899-bd8a-4c6e-8d1e-d261a6d11d67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GAN_model.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=Adam(lr=lr, beta_1=0.5, decay=lr/num_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTlXeJ5xCKJg"
   },
   "source": [
    "#### Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-V7O_HmZaCHA"
   },
   "outputs": [],
   "source": [
    "def prepare_images(G,imageBatch, batch_size):\n",
    "    ''' Select the next batch of images, then randomly generate\n",
    "        noise for the generator to predict on.\n",
    "        Construct class labels for the discriminator, and shuffle\n",
    "        the data'''\n",
    "    noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "    # Generate images using the noise + generator model\n",
    "    genImages = G.predict(noise, verbose=0)\n",
    "    X = np.concatenate((imageBatch, genImages))#Concat real and generated\n",
    "    y = ([1] * batch_size) + ([0] * batch_size)\n",
    "    y = np.reshape(y, (-1,))\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def GAN_output(G,epoch,noise,output):\n",
    "    '''\n",
    "    Visualize the output of the generator model on our benchmark data\n",
    "    Make predictions on the benchmark noise, scale it back\n",
    "    to the range [0, 255], and generate the montage'''\n",
    "    fp = [output, f\"epoch_{epoch + 1:03}_output.png\"]   \n",
    "    images = G.predict(noise)\n",
    "    images = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
    "    images = np.repeat(images, 3, axis=-1)\n",
    "    vis = build_montages(images, (28, 28), (16, 16))[0]\n",
    "    # write the visualization to disk\n",
    "    fp = os.path.sep.join(fp)\n",
    "    res = cv2.imwrite(fp, vis)\n",
    "    print(fp,' ',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BEheZsvBCKJh"
   },
   "outputs": [],
   "source": [
    "def train_gan(G,D,GAN,trainImages,num_epochs,outDir):\n",
    "    benchmarkNoise = np.random.uniform(-1, 1, size=(256, 100))\n",
    "    batch_size = 128\n",
    "    batchesPerEpoch = int(trainImages.shape[0]/batch_size)\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i in range(0, batchesPerEpoch):\n",
    "            imageBatch = trainImages[i*batch_size:(i+1)*batch_size]\n",
    "            X,y = prepare_images(G,imageBatch,batch_size)\n",
    "            # Train the discriminator on the data\n",
    "            D_Loss = D.train_on_batch(X, y)\n",
    "\n",
    "            # Train the generator via the adversarial model by\n",
    "            # (1) generating random noise and \n",
    "            # (2) training generator with the discriminator weights frozen\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 100))\n",
    "            fakeLabels = [1] * batch_size\n",
    "            fakeLabels = np.reshape(fakeLabels, (-1,))\n",
    "            GAN_Loss = GAN.train_on_batch(noise, fakeLabels)\n",
    "            if not i%150:\n",
    "                print(\n",
    "                f\"Epoch {epoch+1}_{i}: D loss={D_Loss:.4f}, GAN loss={GAN_Loss:.4f}\")\n",
    "          \n",
    "            # Write predicted images to disk\n",
    "            if outDir and (i == batchesPerEpoch - 1): # End of epoch\n",
    "                GAN_output(G,epoch,benchmarkNoise,outDir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ybtq1yOCKJh",
    "outputId": "63e61cd8-8323-4706-dddb-ff8923e7291c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1_0: D loss=0.6497, GAN loss=0.5647\n",
      "Epoch 1_150: D loss=0.0003, GAN loss=0.0003\n",
      "Epoch 1_300: D loss=0.4648, GAN loss=1.0464\n",
      "Epoch 1_450: D loss=0.5234, GAN loss=0.7322\n",
      "Images/epoch_001_output.png   False\n",
      "Epoch 2_0: D loss=0.5726, GAN loss=1.3877\n",
      "Epoch 2_150: D loss=0.5650, GAN loss=0.8348\n",
      "Epoch 2_300: D loss=0.5625, GAN loss=0.7761\n",
      "Epoch 2_450: D loss=0.6495, GAN loss=1.5296\n",
      "Images/epoch_002_output.png   False\n",
      "Epoch 3_0: D loss=0.5976, GAN loss=0.7798\n",
      "Epoch 3_150: D loss=0.6183, GAN loss=0.9943\n",
      "Epoch 3_300: D loss=0.6018, GAN loss=1.1032\n",
      "Epoch 3_450: D loss=0.6265, GAN loss=1.1012\n",
      "Images/epoch_003_output.png   False\n",
      "Epoch 4_0: D loss=0.6254, GAN loss=1.0488\n",
      "Epoch 4_150: D loss=0.6521, GAN loss=0.7308\n",
      "Epoch 4_300: D loss=0.6321, GAN loss=0.9932\n",
      "Epoch 4_450: D loss=0.6563, GAN loss=0.5920\n",
      "Images/epoch_004_output.png   False\n",
      "Epoch 5_0: D loss=0.6467, GAN loss=0.9133\n",
      "Epoch 5_150: D loss=0.6391, GAN loss=0.9493\n",
      "Epoch 5_300: D loss=0.6079, GAN loss=0.7393\n",
      "Epoch 5_450: D loss=0.6348, GAN loss=0.7320\n",
      "Images/epoch_005_output.png   False\n",
      "Epoch 6_0: D loss=0.6176, GAN loss=0.8340\n",
      "Epoch 6_150: D loss=0.6570, GAN loss=0.7558\n",
      "Epoch 6_300: D loss=0.6219, GAN loss=0.8340\n",
      "Epoch 6_450: D loss=0.6466, GAN loss=0.7569\n",
      "Images/epoch_006_output.png   False\n",
      "Epoch 7_0: D loss=0.6462, GAN loss=0.7092\n",
      "Epoch 7_150: D loss=0.6464, GAN loss=0.6723\n",
      "Epoch 7_300: D loss=0.6296, GAN loss=0.8781\n",
      "Epoch 7_450: D loss=0.6262, GAN loss=0.8058\n",
      "Images/epoch_007_output.png   False\n",
      "Epoch 8_0: D loss=0.6256, GAN loss=0.9502\n",
      "Epoch 8_150: D loss=0.6381, GAN loss=0.6898\n",
      "Epoch 8_300: D loss=0.6567, GAN loss=0.5454\n",
      "Epoch 8_450: D loss=0.6475, GAN loss=0.9308\n",
      "Images/epoch_008_output.png   False\n",
      "Epoch 9_0: D loss=0.6431, GAN loss=0.8314\n",
      "Epoch 9_150: D loss=0.6434, GAN loss=0.8418\n",
      "Epoch 9_300: D loss=0.6357, GAN loss=0.8343\n",
      "Epoch 9_450: D loss=0.6383, GAN loss=0.8812\n",
      "Images/epoch_009_output.png   False\n",
      "Epoch 10_0: D loss=0.6382, GAN loss=0.7567\n",
      "Epoch 10_150: D loss=0.6863, GAN loss=0.7228\n",
      "Epoch 10_300: D loss=0.6278, GAN loss=0.9832\n",
      "Epoch 10_450: D loss=0.6028, GAN loss=0.7572\n",
      "Images/epoch_010_output.png   False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "output = \"Images\"\n",
    "train_gan(G_model,D_model,GAN_model,\n",
    "          trainImages,\n",
    "          num_epochs,\n",
    "          output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBP8ZIFBaCG-"
   },
   "source": [
    "### References\n",
    "\n",
    "\n",
    "https://www.pyimagesearch.com/2020/11/16/gans-with-keras-and-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_TF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
