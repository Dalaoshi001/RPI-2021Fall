{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential,Model \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import load_model,save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(X_train,y_train), (X_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 60000 training samples, each is 28x28\n",
    "* 10000 test samples, each is 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=[8,8])\n",
    "\n",
    "# Display the first image in training data\n",
    "\n",
    "ax1.imshow(X_train[0,:,:], cmap='gray')\n",
    "ax1.set_title(f'Ground Truth : {y_train[0]}')\n",
    "\n",
    "# Display the first image in testing data\n",
    "\n",
    "ax2.imshow(X_test[0,:,:], cmap='gray')\n",
    "ax2.set_title(f'Ground Truth : {y_test[0]}');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test images of ankle boots labeled as class 9.\n",
    "\n",
    "Grayscale images with pixel values 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "* Reshape each image to 28x28x1.\n",
    "* Convert to float32\n",
    "* Scale to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,  57, 202, 233, 204, 203, 122], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 28,28, 1)\n",
    "X_test = X_test.reshape(-1, 28,28, 1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "X_train[0,16:23,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.22352941, 0.7921569 , 0.9137255 , 0.8       ,\n",
       "       0.79607844, 0.47843137], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "X_train[0,16:23,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot shape  (10000, 10)\n",
      "Original label: 9\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "print('One hot shape ',y_test_one_hot.shape)\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', y_train[0])\n",
    "print('After conversion to one-hot:', y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data into training data and validation data\n",
    "\n",
    "train_X: train model on this data (80% of X_train)  \n",
    "valid_X: used to validate model on this data (20% of X_train)  \n",
    "train_label: labels for train_X (80% of y_train_one_hot)  \n",
    "valid_label: labels for valid_X (20% of y_train_one_hot)  \n",
    "  \n",
    "Note: Still have X_test and y_test_one_hot for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=13)\n",
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "\n",
    "![](TheNetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),\n",
    "                     padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 356,234\n",
      "Trainable params: 356,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters Convolutional layer\n",
    "\n",
    "* nxm dimensions of kernel, \n",
    "* l = number in, \n",
    "* +1 for bias\n",
    "* k = number out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18496"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters conv2d_2\n",
    "# n,m = shape of kernel\n",
    "# l = number of inputs\n",
    "# k = number of outputs\n",
    "n,m,l,k = 3,3,32,64\n",
    "(n*m*l+1)*k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters in fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262272"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,k = 2048,128\n",
    "(l+1)*k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters in output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,k = 128,10\n",
    "(l+1)*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv2d_1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3 = model.get_layer(index=3)\n",
    "layer3.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x200d3e15518>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x200d3e15828>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x200c4b41470>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x200d3e15f28>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x200d3e15748>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x200d39629e8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x200d39c22b0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x200d3983400>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x200d3999b38>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x200d39edcf8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x200d39ce0f0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x200d39edc88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x200d3a39fd0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "\n",
    "Choose:\n",
    "\n",
    "- Optimizer:  Adam  \n",
    "- Loss type: categorical_crossentropy (could use binary cross-entropy)    \n",
    "- Metric: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Keras fit function returns a history object to use later to analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #128,256 # Minibatch size\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 75s 2ms/sample - loss: 0.4663 - acc: 0.8308 - val_loss: 0.3380 - val_acc: 0.8828\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 73s 2ms/sample - loss: 0.2893 - acc: 0.8945 - val_loss: 0.2800 - val_acc: 0.8968\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 81s 2ms/sample - loss: 0.2420 - acc: 0.9122 - val_loss: 0.2469 - val_acc: 0.9095\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2103 - acc: 0.9229 - val_loss: 0.2511 - val_acc: 0.9107\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 81s 2ms/sample - loss: 0.1845 - acc: 0.9315 - val_loss: 0.2291 - val_acc: 0.9165\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 80s 2ms/sample - loss: 0.1593 - acc: 0.9403 - val_loss: 0.2211 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 80s 2ms/sample - loss: 0.1388 - acc: 0.9478 - val_loss: 0.2283 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.1200 - acc: 0.9557 - val_loss: 0.2562 - val_acc: 0.9165\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 44s 909us/sample - loss: 0.1018 - acc: 0.9623 - val_loss: 0.2543 - val_acc: 0.9219\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 42s 882us/sample - loss: 0.0861 - acc: 0.9678 - val_loss: 0.2650 - val_acc: 0.9201\n"
     ]
    }
   ],
   "source": [
    "model_train = model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                        validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2766612820893526\n",
      "Test accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['accuracy']\n",
    "val_accuracy = model_train.history['val_accuracy']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice U-shaped curve in the Loss plot: means the model is overfitting after about epoch 4 or 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Reduce overfitting by using dropout. Dropout randomly turns off a percentage of the unit during training.\n",
    "\n",
    "Number of units to drop is a hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))           \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_dropout = model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,\n",
    "                                verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model\n",
    "\n",
    "We can do a warm restart with the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,\"model_dropout.h5py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, y_test_one_hot, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train_dropout.history['accuracy']\n",
    "val_accuracy = model_train_dropout.history['val_accuracy']\n",
    "loss = model_train_dropout.history['loss']\n",
    "val_loss = model_train_dropout.history['val_loss']\n",
    "epochs = range(len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Classes of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = model.predict(X_test)\n",
    "\n",
    "print(predicted_classes[0,:])\n",
    "print(np.round(predicted_classes[0,:],5))\n",
    "print(predicted_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "print(f'Predicted = {predicted_classes[0]}, label = {y_test[0]}')\n",
    "predicted_classes.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_classes==y_test)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes!=y_test)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predicted_classes,y_test)\n",
    "print(cm)\n",
    "\n",
    "print(f'Accuracy: {np.trace(cm)/np.sum(cm)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = load_model(\"model_dropout.h5py\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval2 = m.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval2[0])\n",
    "print('Test accuracy:', test_eval2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape,y_test_one_hot.shape,predicted_classes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://www.curiousily.com/posts/tensorflow-2-and-keras-quick-start-guide/\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "624px",
    "left": "936px",
    "right": "20px",
    "top": "107px",
    "width": "380px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
