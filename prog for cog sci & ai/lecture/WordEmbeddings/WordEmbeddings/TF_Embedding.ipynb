{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdae21cd-d02c-4656-907f-7f39d15147c8",
   "metadata": {
    "id": "v2goQ7zZ6Jky"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b49b95a-f607-4a69-925d-b62d9d153019",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Hh_uE8lMjm0K",
    "outputId": "033beeb0-ff75-47db-c3a9-b4ad6f02b8ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e7c83-dd4c-4ace-8dcf-69b205c28617",
   "metadata": {
    "id": "bRf7uLyWjm0K"
   },
   "source": [
    "### Embedding layer in Tensorflow\n",
    "\n",
    "The Embedding layer takes at least two arguments:\n",
    "- The number of samples (i.e. words, tokens)\n",
    "- The dimensionality (length) of the embedding vector\n",
    "\n",
    "This layer returns a 3D floating point tensor, of shape (num_samples, sequence_length, embedding_dimensionality). \n",
    "\n",
    "When this layer is instantiated, its weights are initially random. During training, these word vectors will be gradually adjusted via backpropagation, structuring the space into a representation that can be used in other layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86293f8-b746-4f81-b20a-b7138a2da44c",
   "metadata": {
    "id": "AFT3nljCjm0L"
   },
   "source": [
    "### Sentiment prediction using IMDB Movie Reviews\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/imdb_reviews\n",
    "\n",
    "The number of words is restricted to the top 10,000 most common words in the reviews.\n",
    "\n",
    "The reviews are truncated to only 20 words. \n",
    "\n",
    "The model will consist of:\n",
    "\n",
    "- An 8-dimensional embedding for each of the 10,000 words\n",
    "- Flatten layer the tensor to 2D, and  \n",
    "- A single Dense layer to classify a review as favorable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73db6a13-20a8-49e3-a128-e26ebd7b7727",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_NcpB55jm0L",
    "outputId": "1ad29280-8dc9-4825-e2eb-d824c52b2fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 10000 # Number of words to consider as features\n",
    "\n",
    "maxlen = 20 # Cut text after maxlen (among top max_features most common words)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "type(X_train[0]),len(X_train[0]),max(X_train[0])\n",
    "\n",
    "X_train[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516c0eca-ee62-4837-99e4-cec8c411475c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzwwOFjnjm0L",
    "outputId": "85410e5d-e4b2-488c-ffaf-552e4dc9d7d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a40ed4-c7f1-456f-b037-14381ad3cd06",
   "metadata": {
    "id": "wr4e3kKfjm0L"
   },
   "source": [
    "#### Create 2D integer tensor of shape (samples, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191ce972-d305-483c-868c-0ab48eaec75b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo2myv5Djm0L",
    "outputId": "ed386802-37f6-4e3e-c2e8-c714bb2f9df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 20) (25000, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "print(X_train.shape,X_test.shape)\n",
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d5d90-3692-43f9-ab4e-d8bbbfed7564",
   "metadata": {
    "id": "2kHADgsUjm0L"
   },
   "source": [
    "#### Create Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30434b53-ce1d-4d6b-a544-1410f18fe6be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En54hcUsjm0L",
    "outputId": "ce8993b9-1338-435c-e09f-529e93ea340c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# Output shape (samples, maxlen, 8)\n",
    "model.add(Flatten()) # Flatten into a 2D tensor of shape (samples, maxlen * 8)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d5fcc-dfb8-40b2-8cd5-f28e2c09f061",
   "metadata": {
    "id": "JbuWTLQ-jm0L"
   },
   "source": [
    "#### Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045d5bdd-e386-4681-b0a1-66ce9c7f26e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j05XO2Xdjm0L",
    "outputId": "e9664e78-a495-4224-fc8b-cd4f09409845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6762 - acc: 0.6004 - val_loss: 0.6314 - val_acc: 0.6892\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5505 - acc: 0.7459 - val_loss: 0.5306 - val_acc: 0.7276\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4657 - acc: 0.7850 - val_loss: 0.4999 - val_acc: 0.7464\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4272 - acc: 0.8043 - val_loss: 0.4933 - val_acc: 0.7504\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4029 - acc: 0.8184 - val_loss: 0.4948 - val_acc: 0.7528\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3838 - acc: 0.8288 - val_loss: 0.4980 - val_acc: 0.7554\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3667 - acc: 0.8382 - val_loss: 0.4996 - val_acc: 0.7590\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3497 - acc: 0.8483 - val_loss: 0.5036 - val_acc: 0.7568\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3324 - acc: 0.8572 - val_loss: 0.5098 - val_acc: 0.7552\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3149 - acc: 0.8676 - val_loss: 0.5165 - val_acc: 0.7588\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3899da7-259a-469b-974e-1bc7641a31ea",
   "metadata": {
    "id": "cNQ80P7zjm0L"
   },
   "source": [
    "#### Compute classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0781926d-623f-42da-824d-67b7879e7354",
   "metadata": {
    "id": "b3ekaY9Bjm0L"
   },
   "outputs": [],
   "source": [
    "def accuracy(x,y):\n",
    "    y_hat = model.predict(x)\n",
    "    foo = np.array([1 if i > .5 else 0 for i in y_hat[:,0] ])\n",
    "    return np.sum(foo == y)/len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098f20a8-f23e-441f-b3b5-5e146fcc0066",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFgB89_Bjm0L",
    "outputId": "cbf13ffd-093b-46f4-a62b-c35089cb1592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85516, 0.76136)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(X_train,y_train),accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efa744-5dc5-4c8d-a79c-dd57a6734b4b",
   "metadata": {
    "id": "u_EaplDojm0L"
   },
   "source": [
    "This model with a single Dense layer treats each word in the input sequence separately. Inter-word relationships and structure sentence are not taken into account.\n",
    "\n",
    "We could add recurrent layers or 1D convolutional layers after the embedded sequences to learn features that take into account each sequence as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a00c51-f6f2-41f1-84a2-60a20da0e48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
