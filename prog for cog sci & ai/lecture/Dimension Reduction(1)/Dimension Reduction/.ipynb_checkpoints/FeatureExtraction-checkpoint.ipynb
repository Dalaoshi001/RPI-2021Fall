{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction \n",
    " \n",
    "* Transforms the features into a lower dimensional feature space.\n",
    "    - Information about the dataset is compressed.\n",
    "    - Feature selection keeps the same features, feature extraction creates new features\n",
    "    - The transformed features then can be used in regression and classification tasks\n",
    "\n",
    "* Methods\n",
    "    - Linear Discriminant Analysis\n",
    "    - Principal Component Analysis\n",
    "    - Partial Least Squares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wine data\n",
    "\n",
    "* Class wine into one of three classes \n",
    "* 13 numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_results import plot_results\n",
    "from classification_results import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "177    14.13        4.10  2.74          24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "173        0.61                  0.52             1.06              7.7  0.64   \n",
       "174        0.75                  0.43             1.41              7.3  0.70   \n",
       "175        0.69                  0.43             1.35             10.2  0.59   \n",
       "176        0.68                  0.53             1.46              9.3  0.60   \n",
       "177        0.76                  0.56             1.35              9.2  0.61   \n",
       "\n",
       "     OD280  Proline  Customer_Segment  \n",
       "173   1.74      740                 3  \n",
       "174   1.56      750                 3  \n",
       "175   1.56      835                 3  \n",
       "176   1.62      840                 3  \n",
       "177   1.60      560                 3  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('Wine.csv')\n",
    "wine.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (36, 13) (142,) (36,)\n"
     ]
    }
   ],
   "source": [
    "X = wine.iloc[:, 0:13].values\n",
    "y = wine.iloc[:, 13].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA)\n",
    "\n",
    "* LDA is used for classification and feature extraction\n",
    "    - A supervised dimensionality reduction technique for maximizing class separability\n",
    "        - Uses information provided by the class labels to aid discriminating\n",
    "    - Extracted feature vectors indicate the direction of maximimum class variability and separation\n",
    "\n",
    "#### Assumptions\n",
    "\n",
    "* The classes have Normal distributions  \n",
    "* The classes have identical covariance matrices\n",
    "* The features are statistically independent of each other.\n",
    "* LDA for dimension reduction can work fairly well even if these assumptions are violated.\n",
    "    - LDA classification is also fairly robust to the distribution of the classes\n",
    "\n",
    "![](LDA.png)\n",
    "$$\\text{Figure 1. Two Classes}$$\n",
    "\n",
    "* LDA computes the directions (“linear discriminants”) that will represent the axes that that maximize the separation between multiple classes.\n",
    "\n",
    "* Projecting the data onto the X-axis maximizes the class separation.\n",
    "    - LD1 linear discriminant on the x-axis (LD 1) would do a good job of separating the two normal distributed classes. \n",
    "* The linear discriminant LD 2 captures a lot of the variance in the dataset but would fail as a good linear discriminant (i.e. projection) since it does not capture any of the information that discriminates the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Algorithm\n",
    "\n",
    "* LDA computes means and scatter matricies on standardize data. The eigenvalues and eigenvectors of the combined matrices are used to project the data onto the lower dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Create mean of features grouped by class\n",
    "\n",
    "*  LDA takes class label information into account, which is represented in the form of the mean vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.9384, -0.3007,  0.2821, -0.7201,  0.5035,  0.8546,  0.9448,\n",
       "        -0.6015,  0.5789,  0.2062,  0.4774,  0.7832,  1.1618]),\n",
       " array([-0.8645, -0.3413, -0.3877,  0.253 , -0.3325, -0.0674,  0.057 ,\n",
       "        -0.0013,  0.0322, -0.8457,  0.4096,  0.1992, -0.6927]),\n",
       " array([ 0.1361,  0.8839,  0.2326,  0.5112, -0.124 , -0.9559, -1.2541,\n",
       "         0.7459, -0.7643,  1.0136, -1.2048, -1.2675, -0.3979])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVs = [np.mean(X_train_std[y_train == label], axis=0) for label in [1,2,3]]\n",
    "MVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Create the Within Class Scatter Matrix\n",
    "\n",
    "* Individual Class scaled scatter matrix is just the covariance matrix $S_i$\n",
    "$$S_w = \\sum_CS_c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled within-class scatter matrix: 13x13\n"
     ]
    }
   ],
   "source": [
    "d = X_train.shape[1] # number of features\n",
    "S_W = np.zeros((d, d))\n",
    "for label, mv in zip(range(1, 4), MVs):\n",
    "    class_scatter = np.cov(X_train_std[y_train == label].T)\n",
    "    S_W += class_scatter\n",
    "print('Scaled within-class scatter matrix: %sx%s' % (S_W.shape[0],\n",
    "                                                     S_W.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Create the Between Class Scatter Matrix\n",
    "\n",
    "$$S_B = \\sum_{i = 1}^Cn_i(m_i - m)(m_i - m)^T$$\n",
    "\n",
    "$m_i$ is the Class mean  \n",
    "m is the overall mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between-class scatter matrix: 13x13\n"
     ]
    }
   ],
   "source": [
    "overall_mean = np.mean(X_train_std, axis=0)\n",
    "\n",
    "S_B = np.zeros((d, d))\n",
    "for i, mv in enumerate(MVs):\n",
    "    n = X_train[y_train == i + 1, :].shape[0]\n",
    "    mv = mv.reshape(d, 1)  # make column vector\n",
    "    overall_mean = overall_mean.reshape(d, 1)  # make column vector\n",
    "    S_B += n * (mv - overall_mean).dot((mv - overall_mean).T)\n",
    "\n",
    "print('Between-class scatter matrix: %sx%s' % (S_B.shape[0], S_B.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Compute the eigenvectors and corresponding eigenvalues of the matrix $S_W^{-1}S_B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[407.869109656997,\n",
       " 204.72244692412642,\n",
       " 5.684341886080802e-14,\n",
       " 5.5140718517138425e-14,\n",
       " 5.5140718517138425e-14,\n",
       " 3.559314771096042e-14,\n",
       " 2.2070598160548366e-14,\n",
       " 2.2070598160548366e-14,\n",
       " 1.5294266009607075e-14,\n",
       " 1.5294266009607075e-14,\n",
       " 4.5113403048747506e-15,\n",
       " 1.2541085023712623e-15,\n",
       " 1.2541085023712623e-15]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "               for i in range(len(eigen_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eigen_pairs = sorted(eigen_pairs, key=lambda k: k[0], reverse=True)\n",
    "eigen_vals = list(map(lambda x: x[0],eigen_pairs))\n",
    "eigen_vecs = list(map(lambda x: x[1],eigen_pairs))\n",
    "list(eigen_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Choose the k eigenvectors that correspond to the k largest eigenvalues.\n",
    "\n",
    "* Construct W:  a d × k transformation matrix  \n",
    "* The eigenvectors are the columns W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1102, -0.4015],\n",
       "       [ 0.0983, -0.1896],\n",
       "       [ 0.0526, -0.4505],\n",
       "       [ 0.1545,  0.3686],\n",
       "       [ 0.0044, -0.0449],\n",
       "       [ 0.1678, -0.0067],\n",
       "       [-0.793 ,  0.3018],\n",
       "       [-0.0968,  0.1012],\n",
       "       [ 0.0141,  0.0959],\n",
       "       [ 0.3007, -0.2383],\n",
       "       [-0.0973,  0.2172],\n",
       "       [-0.3288, -0.0496],\n",
       "       [-0.2776, -0.4951]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.zeros((13,2))\n",
    "W = np.hstack((np.array(eigen_vecs[0]).reshape(-1,1).real,\n",
    "               np.array(eigen_vecs[1]).reshape(-1,1).real))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Project the data onto the new feature subspace using the transformation matrix W, 142x13 X 13x2 = 142x2\n",
    "$$ X_{new} = X_{train} \\cdot{W}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lda = X_train_std.dot(W)\n",
    "X_train_lda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data in new feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'b', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_lda[y_train == l, 0],\n",
    "                X_train_lda[y_train == l, 1] * (-1),\n",
    "                c=c, label=l, marker=m)\n",
    "\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('LD 2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA for Dimension Reduction in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and transform the Training data to 2-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 2), (36, 2))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_lda = LDA(n_components = 2)\n",
    "X_train_lda = model_lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = model_lda.transform(X_test_std)\n",
    "X_train_lda.shape,X_test_lda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a Logistic Regression model using all thirteen prdictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "\n",
    "model_lr = LogisticRegression(random_state = 0)\n",
    "model_lr.fit(X_train_std, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model_lr.predict(X_test_std)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a Logistic Regression model with the reduced Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  0 10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to reduced feature space\n",
    "\n",
    "model_lr2 = LogisticRegression(random_state = 0)\n",
    "model_lr2.fit(X_train_lda, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model_lr2.predict(X_test_lda)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "372px",
    "left": "809px",
    "right": "20px",
    "top": "13px",
    "width": "492px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
